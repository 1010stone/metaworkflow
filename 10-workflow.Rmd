# Workflow

## Platform for metabolomics

Here is a list for related open source [projects](http://strimmerlab.org/notes/mass-spectrometry.html)

### XCMS online

[XCMS online](https://xcmsonline.scripps.edu/landing_page.php?pgcontent=mainPage) is hosted by Scripps Institute. If your datasets are not large, XCMS online would be the best option for you. Recently they updated the online version to support more functions for systems biology. They use metlin and iso metlin to annotate the MS/MS data. Pathway analysis is also supported. Besides, to accelerate the process, xcms online employed stream (windows only). You could use stream to connect your instrument workstation to their server and process the data along with the data acquisition automate. They also developed apps for xcms online, but I think apps for slack would be even cooler to control the data processing.

### PRIMe

[PRIMe](http://prime.psc.riken.jp/Metabolomics_Software/) is from RIKEN and UC Davis. They update their database frequently[@tsugawa2016]. It supports mzML and major MS vendor formats. They defined own file format ABF and eco-system for omics studies. The software are updated almost everyday. You could use MS-DIAL for untargeted analysis and MRMOROBS for targeted analysis. For annotation, they developed MS-FINDER and statistic tools with excel. This platform could replaced the dear software from company and well prepared for MS/MS data analysis and lipidomics. They are open source, work on Windows and also could run within mathmamtics. However, they don't cover pathway analysis. Another feature is they always show the most recently spectral records from public repositories. You could always get the updated MSP spectra files for your own data analysis.

If you make GC-MS based metabolomics, this paper[@matsuo2017] could be nice start.

### OpenMS

[OpenMS](https://www.openms.de/) is another good platform for mass spectrum data analysis developed with C++. You could use them as plugin of [KNIME](https://www.knime.org/). I suggest anyone who want to be a data scientist to get familiar with platform like KNIME because they supplied various API for different programme language, which is easy to use and show every steps for others. Also TOPPView in OpenMS could be the best software to visualize the MS data. You could always use the metabolomics workflow to train starter about details in data processing. pyOpenMS and OpenSWATH are also used in this platform. If you want to turn into industry, this platform fit you best because you might get a clear idea about solution and workflow. 

### MZmine 2

[MZmine 2](http://mzmine.github.io/) has three version developed on Java platform and the lastest version is included into [MSDK](https://msdk.github.io/). Similar function could be found from MZmine 2 as shown in XCMS online. However, MZmine 2 do not have pathway analysis. You could use metaboanalyst for that purpose. Actually, you could go into MSDK to find similar function supplied by [ProteoSuite](http://www.proteosuite.org) and [Openchrom](https://www.openchrom.net/). If you are a experienced coder for Java, you should start here.

### XCMS

[xcms](https://bioconductor.org/packages/release/bioc/html/xcms.html) is different from xcms online while they might share the same code. I used it almost every data to run local metabolomics data analysis. Recently, they will change their version to xcms 3 with major update for object class. Their data format would integrate into the MSnbase package and the parameters would be easy to set up for each step. Normally, I will use msconvert-IPO-xcms-xMSannotator-metaboanalyst as workflow to process the offline data. It could accelerate the process by parallel processing. However, if you are not familiar with R, you would better to choose some software above.

### Emory MaHPIC

This platform is composed by several R packages from Emory University including [apLCMS](https://sourceforge.net/projects/aplcms/) to collect the data, [xMSanalyzer](https://sourceforge.net/projects/xmsanalyzer/) to handle automated pipeline for large-scale, non-targeted metabolomics data, [xMSannotator](https://sourceforge.net/projects/xmsannotator/) for annotation of LC-MS data and [Mummichog](https://code.google.com/archive/p/atcg/wikis/mummichog_for_metabolomics.wiki) for pathway and network analysis for high-throughput metabolomics. This platform would be preferred by someone from environmental science to study exposome. I always use xMSannotator to annotate the LC-MS data.

### DIA data analysis

[Skyline](https://skyline.ms/project/home/software/Skyline/begin.view) is a freely-available and open source Windows client application for building Selected Reaction Monitoring (SRM) / Multiple Reaction Monitoring (MRM), Parallel Reaction Monitoring (PRM - Targeted MS/MS), Data Independent Acquisition (DIA/SWATH) and targeted DDA with MS1 quantitative methods and analyzing the resulting mass spectrometer data.

[MSstats](https://github.com/MeenaChoi/MSstats) is an R-based/Bioconductor package for statistical relative quantification of peptides and proteins in mass spectrometry-based proteomic experiments. It is applicable to multiple types of sample preparation, including label-free workflows, workflows that use stable isotope labeled reference proteins and peptides, and work-flows that use fractionation. It is applicable to targeted Selected Reactin Monitoring(SRM), Data-Dependent Acquisiton(DDA or shotgun), and Data-Independent Acquisition(DIA or SWATH-MS). This github page is for sharing source and testing. 

MS-DAIL is also an option for DIA.

### Others

- [MAVEN](http://genomics-pubs.princeton.edu/mzroll/index.php?show=index) from Princeton University

- [MAIT](https://www.bioconductor.org/packages/release/bioc/html/MAIT.html) based on xcms and you could find source code [here](https://github.com/jpgroup/MAIT)[@fernandez-albert2014a].

- [metabolomics](https://github.com/cran/metabolomics) is a CRAN package for analysis of metabolomics data.

- [LipidFinder](https://github.com/ODonnell-Lipidomics/LipidFinder) A computational workflow for discovery of new lipid molecular species

- [enviGCMS](https://github.com/yufree/enviGCMS) from environmental non-targeted analysis.

- [pySM](https://github.com/alexandrovteam/pySM)  provides a reference implementation of our pipeline for False Discovery Rate-controlled metabolite annotation of high-resolution imaging mass spectrometry data.

- [MetabolomeExpress](https://www.metabolome-express.org/) a public place to process, interpret and share GC/MS metabolomics datasets. 
 
- [PhenoMeNal](https://portal.phenomenal-h2020.eu/home) is an easy-to-use, cloud-based metabolomic research environment.

- [MetAlign&MSClust](https://www.wur.nl/en/show/MetAlign.htm)

- [MetaboliteDetector](http://md.tu-bs.de/node/3) is a QT4 based software package for the analysis of GC/MS based metabolomics data.

## Data sharing

See this paper[@haug2017]:

- [MetaboLights](http://www.ebi.ac.uk/metabolights/) EU based

- [The Metabolomics Workbench](http://www.metabolomicsworkbench.org/) US based

- [MetabolomeXchange](http://www.metabolomexchange.org/site/) search engine

- [W4M[@guitton2017]](http://workflow4metabolomics.org/)

## Contest

- [CASMI](http://www.casmi-contest.org/) predict smail molecular contest

## Demo

# Demo

```{r setup, include=FALSE}
knitr::opts_chunk$set(cache = TRUE,warning = F,message = F)
```

## Project Setup

I suggest building your data analysis projects in RStudio(Click File - New project - New dictionary - Empty project). Then assign a name for your project. I also recommend the following tips if you are familiar with it.

- Use [git](https://git-scm.com/)/[github](https://github.com/) to make version control of your code and sync your project online.

- NOT use your name for your project because other peoples might cooperate with you and someone might check your data when you publish your papers. Each project should be a work for one paper or one chapter in your thesis.

- Use **workflow** document(txt or doc) in your project to record all of the steps and code you performed for this project. Treat this document as digital version of your experiment notebook

- Use **data** folder in your project folder for the raw data and the results you get in data analysis

- Use **figure** folder in your project folder for the figure

- Use **munuscript** folder in your project folder for the manuscript (you could write paper in rstudio with the help of template in [Rmarkdown](https://github.com/rstudio/rticles))

- Just double click **[yourprojectname].Rproj** to start your project


## Data input

**xcms** does not support all of the Raw files from every mass spectrometry manufacturers. You need to convert your Raw data into some open-source [data format](https://en.wikipedia.org/wiki/Mass_spectrometry_data_format) such as mzData, mzXML or CDF files. The tool is **MScovert** from [**ProteoWizard**](http://proteowizard.sourceforge.net/).

## Optimization

IPO package could be used to optimaze the parameters for XCMS. Try the following code.

```{r IPOpos,eval=F}
library(IPO)
library(xcms)
peakpickingParameters <- getDefaultXcmsSetStartingParams('centWave')
path <- list.files('D:/metademo/data/oq/',full.names = T,recursive = T)
# change to 5 for obitrap
peakpickingParameters$ppm <- 15
resultPeakpicking <- 
  optimizeXcmsSet(files = path[c(1,2,3)], 
                  params = peakpickingParameters,
                  nSlaves = 1,
                  subdir = NULL)

optimizedXcmsSetObject <- resultPeakpicking$best_settings$xset
retcorGroupParameters <- getDefaultRetGroupStartingParams()
resultRetcorGroup <-
  optimizeRetGroup(xset = optimizedXcmsSetObject, 
                   params = retcorGroupParameters, 
                   subdir = NULL)
writeRScript(resultPeakpicking$best_settings$parameters, 
             resultRetcorGroup$best_settings)
para <- capture.output(writeRScript(resultPeakpicking$best_settings$parameters, resultRetcorGroup$best_settings), type = "message")
save(para,file = 'para.RData')
sessionInfo()
```

## Wrap function

Here we would use the optimized parameters for peak picking, retention time correction and peaks filling.

```{r eval=F}
library(xcms)
library(Rmpi)
library(stringr)
getrtmz <- function(path,index = NULL){
  load('para.RData')
peakwidth <- as.numeric(unlist(str_extract_all(para[grepl('peakwidth',para)],'\\d+\\.*\\d*')))
ppm <- as.numeric(unlist(str_extract_all(para[grepl('ppm',para)],'\\d+')))
noise <- as.numeric(unlist(str_extract_all(para[grepl('noise',para)],'\\d+')))
snthresh <- as.numeric(unlist(str_extract_all(para[grepl('snthresh',para)],'\\d+')))
mzdiff <- as.numeric(unlist(str_extract_all(para[grepl('mzdiff',para)],'\\d+\\.*\\d*')))
prefilter <- as.numeric(unlist(str_extract_all(para[grepl('prefilter',para)],'\\d+\\.*\\d*')))
integrate <- as.numeric(unlist(str_extract_all(para[grepl('integrate',para)],'\\d+')))
profStep <- round(as.numeric(unlist(str_extract_all(para[grepl('profStep',para)],'\\d+\\.*\\d*'))),1)
center <- as.numeric(unlist(str_extract_all(para[grepl('center',para)],'\\d+')))
response <- as.numeric(unlist(str_extract_all(para[grepl('response',para)],'\\d+')))
gapInit <- as.numeric(unlist(str_extract_all(para[grepl('gapInit',para)],'\\d+\\.*\\d*')))
gapExtend <- as.numeric(unlist(str_extract_all(para[grepl('gapExtend',para)],'\\d+\\.*\\d*')))
factorDiag <- as.numeric(unlist(str_extract_all(para[grepl('factorDiag',para)],'\\d+')))
factorGap <- as.numeric(unlist(str_extract_all(para[grepl('factorGap',para)],'\\d+')))
localAlignment <- as.numeric(unlist(str_extract_all(para[grepl('localAlignment',para)],'\\d+')))
bw <- as.numeric(unlist(str_extract_all(para[grepl('bw',para)],'\\d+\\.*\\d*')))
mzwid <- as.numeric(unlist(str_extract_all(para[grepl('mzwid',para)],'\\d+\\.*\\d*')))
minfrac <- as.numeric(unlist(str_extract_all(para[grepl('minfrac',para)],'\\d+\\.*\\d*')))
minsamp <- as.numeric(unlist(str_extract_all(para[grepl('minsamp',para)],'\\d+')))
max <-  as.numeric(unlist(str_extract_all(para[grepl('max',para)],'\\d+')))
  files <- list.files(path,full.names = T,recursive = T)
  if(!is.null(index)){
    files <- files[index]
  }
  xset <- xcmsSet(files,
  method = "centWave",
  peakwidth       = peakwidth,
  ppm             = ppm,
  noise           = noise,
  snthresh        = snthresh,
  mzdiff          = mzdiff,
  prefilter       = prefilter,
  mzCenterFun     = "wMean",
  integrate       = integrate,
  fitgauss        = FALSE,
  verbose.columns = FALSE)
xset <- retcor( 
  xset,
  method         = "obiwarp",
  plottype       = "none",
  distFunc       = "cor_opt",
  profStep       = profStep,
  center         = center,
  response       = response,
  gapInit        = gapInit,
  gapExtend      = gapExtend,
  factorDiag     = factorDiag,
  factorGap      = factorGap,
  localAlignment = localAlignment)
xset <- group( 
  xset,
  method  = "density",
  bw      = bw,
  mzwid   = mzwid,
  minfrac = minfrac,
  minsamp = minsamp,
  max     = max)

xset <- fillPeaks(xset)
return(xset)
}
```

### Peak picking

The first step to process the MS data is that find the peaks against the noises. In **xcms**, all of related staffs are handled by *xcmsSet* function. 

For any functions in **xcms** or **R**, you could get their documents by type `?` before certain function. Another geek way is input the name of the function in the console of Rstudio and press F1 for help.

```{r help,eval=F}
?xcmsSet
```

In the document of *xcmsset*, we could set the sample classes, profmethod, profparam, polarity,etc. In the online version, such configurations are shown in certain windows. In the local analysis environment, such parameters are setup by yourselves. However, I think the default configurations could satisfied most of the analysis because related information should have been recorded in your Raw data and **xcms** could find them. All you need to do is that show the data dictionary for *xcmsSet*. 

If your data have many groups such as control and treated group, just put them in separate subfolder of the data folder and *xcmsSet* would read them as separated groups.

### Data correction

Reasons of data correction might come from many aspects such as the unstable instrument and pollution on column. In **xcms**, the most important correction is retention time correction. Remember the original retention time might changed and use another object to save the new object.

### Peaks filling

After the retention time correction, filling the missing peaks could be done by *fillpeaks*. Peaks filling could avoid two many NAs for false statistical analysis. The algorithm could use the baseline signal to impute the data.

## Peaks list

Then we could extract the peaks list from `xcmsSet` objects.

```{r eval=F}
library(enviGCMS)
# get the xcmsset object
neg <- getrtmz('D:/metademo/data/')
# back up the xcmsset object
save(neg,file = 'neg.Rdata')
# get the number
npeaks <- nrow(neg@groups)
# get the EIC, boxplot and diffreport, eixmax should be equal to the numbers of peaks groups in the pos objects 
report <- CAMERA::annotateDiffreport(neg,filebase = 'peaklistneg',metlin = T, eicmax = npeaks, classeic = neg@phenoData$class)
# save the report as a csv file
write.csv(report,file = 'all.csv')
```

## Peaks filtering

After we get the peaks list, it's nessary to filter the peaks list to retain the peaks with high quality for further analysis. Normally, we could use the relative standard deviation of blank and pooled QC samples to control the peaks list.

```{r eval=F}
load('neg.Rdata')
# get the peak intensity, m/z, retention time and group information as list
mzrt <- enviGCMS::getmzrt(neg)
# get the mean and rsd for each group
mzrtm <- enviGCMS::getdoe(mzrt)
gm <- mzrtm$groupmean
gr <- mzrtm$grouprsd
# find the blank group and pool QC group
blk <- grepl('k',colnames(gm))
pqc <- grepl('q',colnames(gm))
# filter by pool QC and blank's group mean intensity(pool QC should larger than three times of blank), return numbers and index
sum(indexmean <- apply(gm,1,function(x) all(x[pqc]>= 3*x[blk])))
# filt by pool qc rsd%, return numbers and index
rsdcf <- 30
sum(indexrsd <- apply(gr,1,function(x) ifelse(is.na(x[pqc]),T,x[pqc]<rsdcf)))
# overlap with rsd% and mean filter
sum(index <- indexmean&indexrsd)

# new list, update group and remove pool qc/blk
qcindex <- grepl('k',mzrt$group$class) | grepl('q',mzrt$group$class)
mzrtfilter <- list(data = mzrt$data[index,!qcindex],
                   mz = mzrt$mz[index],
                   rt = mzrt$rt[index],
                   group = droplevels(mzrt$group$class[!qcindex,drop =T]))
# get the filtered csv
enviGCMS::getupload(mzrtfilter,name = 'peakfilter')

```

## Normalization (Optional)

Normailizaiton is nesscery if you data are collected at different batch or runned in differen instrument parameters.

```{r eval=F}
# visulize the batch effect
mzrtsim::rlaplot(mzrt$data,lv = mzrt$group$class)
mzrtsim::ridgesplot(mzrt$data,lv = mzrt$group$class)
# get the simulation data and test on NOREVA
sim <- mzrtsim::simmzrt(mzrt$data)
mzrtsim::simdata(sim)
# correct the batch effect by sva
mzrtcor <- mzrtsim::svacor(mzrt$data,lv = mzrt$group$class)
# visulize the batch effect correction
li <- mzrtsim::limmaplot(mzrtcor,lv = mzrt$group$class)
# return the corrected data
mzrt$data <- mzrtcor$dataCorrected
```

## Statistic analysis

Here we could use `caret` package to perform statistical analysis.

```{r eval=F}
library(caret)
## Spliting data
trainIndex <- createDataPartition(mzrtfilter$data, p = .8, 
                                  list = FALSE, 
                                  times = 1)
## Get the training and testing datasets
Train <- data[ trainIndex,]
Test  <- data[-trainIndex,]
## Set the cross validation method
fitControl <- trainControl(## 10-fold CV
                           method = "repeatedcv",
                           number = 10,
                           ## repeated ten times
                           repeats = 10)
# extra papameters for GBM 
gbmGrid <-  expand.grid(interaction.depth = c(1, 5, 9), 
                        n.trees = (1:30)*50, 
                        shrinkage = 0.1,
                        n.minobsinnode = 20)

set.seed(825)
gbmFit <- train(mzrtfilter$group ~ ., data = training, 
                 method = "gbm", 
                 trControl = fitControl, 
                 verbose = FALSE, 
                 ## Now specify the exact models 
                 ## to evaluate:
                 tuneGrid = gbmGrid)
# show the fitting process
plot(gbmFit)  
# ANOVA analysis for model selection
anova(fit1,fit2)
# find the important variables
Imp <- varImp(fit)
plot(Imp)
```

## Annotation

Here I use `xMSannotator` package to make annotation with HMDB as reference database.

```{r annotation, eval=F}
library(xMSannotator)
num_nodes = 10
data("adduct_weights")
negsub <- getrtmz('D:/metademo/data/oq/')
anno <- xsetplus::fanno(negsub,outloc = 'D:/metademo/anno',mode = 'neg')
```

## Pathway Analysis

We could output the files for online pathway analysis with mummichog algorithm.

```{r pathway, eval=F}
# get the file
xsetplus::mumdata(neg,lv = mzrt$group$class)
# http://mummichog.org/index.html
# mummichog1 -f 'test.txt' -o myResult
```

## MetaboAnalyst

Actully, after you perform data correction, you have got the data matrix for statistic analysis. You might choose [**MetaboAnalyst**](http://www.metaboanalyst.ca/MetaboAnalyst/faces/docs/Contact.xhtml) online or offline to make furthor analysis, which supplied more statistical choices than xcms.

The input data format for **MetaboAnalyst** should be rows for peaks and colomns for samples. You could also add groups infomation if possible. Use the following code to get the data for analysis.

```{r MetaboAnalyst,eval=F}
# get the csv file for Metaboanalyst.ca
enviGCMS::getupload(neg,name = 'metabo')
```

## Summary

This is the offline metaboliomics data process workflow. For each study, details would be different and F1 is always your best friend. 

Enjoy yourself in data mining!
